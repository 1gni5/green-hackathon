{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "optimizer: str = 'adam'\n",
    "epochs: int = 5\n",
    "batch_size: int = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jules/Projects/notebooks/env/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load the California housing dataset\n",
    "california_housing = fetch_california_housing()\n",
    "X = california_housing.data\n",
    "y = california_housing.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the regression model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1))  # Linear activation for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'get_non_trainable_parameters', 'get_trainable_parameters', 'serialize']\n",
      "Epoch 1/5\n",
      "233/233 [==============================] - 0s 845us/step - loss: 1.1221 - val_loss: 0.5289\n",
      "Epoch 2/5\n",
      "233/233 [==============================] - 0s 723us/step - loss: 0.4542 - val_loss: 0.4406\n",
      "Epoch 3/5\n",
      "233/233 [==============================] - 0s 611us/step - loss: 0.3921 - val_loss: 0.4215\n",
      "Epoch 4/5\n",
      "233/233 [==============================] - 0s 595us/step - loss: 0.3700 - val_loss: 0.4094\n",
      "Epoch 5/5\n",
      "233/233 [==============================] - 0s 585us/step - loss: 0.3596 - val_loss: 0.4061\n"
     ]
    }
   ],
   "source": [
    "from codecarbon import EmissionsTracker\n",
    "from examples.serializer import Serializer\n",
    "\n",
    "# Serialize the model\n",
    "serializer = Serializer()\n",
    "row = serializer.serialize(model, epochs, batch_size)\n",
    "\n",
    "# Start the emissions tracker\n",
    "tracker = EmissionsTracker(log_level='critical')\n",
    "tracker.start()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)\n",
    "\n",
    "# Save the model carbon emissions\n",
    "row['co2'] = tracker.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 358us/step - loss: 0.3682\n",
      "Test mean squared error: 0.3681676685810089\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test mean squared error: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import DictWriter\n",
    "\n",
    "# Save the model metadata\n",
    "with open('results.csv', 'a') as f:\n",
    "    writer = DictWriter(f, fieldnames=row.keys())\n",
    "    writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
